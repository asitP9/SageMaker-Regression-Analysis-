{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifeExpectancyPrediction_Train=pd.read_csv('train.csv')\n",
    "lifeExpectancyPrediction_Test=pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifeExpectancyPrediction_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Poly = lifeExpectancyPrediction_Train.drop(['TARGET_LifeExpectancy', 'ID'], axis=1)\n",
    "Y_Train_Poly = lifeExpectancyPrediction_Train[['TARGET_LifeExpectancy']]\n",
    "X_Test_Poly = lifeExpectancyPrediction_Test.drop('ID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "linReg = linear_model.LinearRegression(normalize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-weight:bold\">If i do degree=4 all the majority prediction comes to be nearly 68,which is not diverse, but given the degree 3, prediction coming from 50 to 80, which is pretty much diverse</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polyFeat = PolynomialFeatures(degree=2, include_bias=True)\n",
    "polyTrainX = polyFeat.fit_transform(X_Train_Poly)\n",
    "polyTestX = polyFeat.fit_transform(X_Test_Poly)\n",
    "linReg.fit(polyTrainX, Y_Train_Poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linReg.intercept_)\n",
    "print(linReg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predYRm_Poly = linReg.predict(polyTestX)\n",
    "predictedResults=pd.DataFrame(predYRm_Poly, columns=['Predicted Life Expectancy_Polynomial']).to_csv('polynomial_prediction.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "number_splits = 10\n",
    "kFold = model_selection.KFold(n_splits=number_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lRegPara = np.linspace(0.001,.5,num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "plt.figure()\n",
    "lResults = np.zeros((number_splits,len(lRegPara)))\n",
    "nsplit = 0\n",
    "for trainIndex, validIndex in kFold.split(X_Train_Poly):\n",
    "# Get the training and validation data\n",
    "    trainX_Regularization = np.array(X_Train_Poly.loc[trainIndex])\n",
    "    trainY_Regularization = np.array(Y_Train_Poly.loc[trainIndex])\n",
    "    validX_Regularization = np.array(X_Train_Poly.loc[validIndex])\n",
    "    validY_Regularization = np.array(Y_Train_Poly.loc[validIndex])\n",
    "    \n",
    "    \n",
    "# This is where you're polynomial model is used!\n",
    "    polyFitTrainX = polyFeat.fit_transform(trainX_Regularization)\n",
    "    polyFitValidX = polyFeat.fit_transform(validX_Regularization)\n",
    "    for j , regPara in enumerate(lRegPara):\n",
    "        polyRidgeReg = linear_model.Ridge(alpha=regPara, normalize=True)\n",
    "        polyRidgeReg.fit(polyFitTrainX, trainY_Regularization)\n",
    "        predY = polyRidgeReg.predict(polyFitValidX)\n",
    "        mse = mean_squared_error(validY_Regularization, predY)\n",
    "        lResults[nsplit, j] = (mse)        \n",
    "        \n",
    "    plt.plot(lRegPara, lResults[nsplit, :], label='Fold '+str(nsplit+1))\n",
    "    nsplit = nsplit + 1\n",
    "    \n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.errorbar(lRegPara, np.mean(lResults,axis=0), yerr=np.std(lResults,axis=0),capsize=3)\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Average MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
